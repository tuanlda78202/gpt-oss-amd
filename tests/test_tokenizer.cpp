// test_tokenizer.cpp â€” Minimal encode/roundtrip tester for tokenizer.bin
//
// Build:
//   gcc -O3 -DTESTING -o test_tokenizer test_tokenizer.cpp -lm
//
// Run:
//   ./test_tokenizer -t tokenizer.bin -i "Hello world" [-r]
//   ./test_tokenizer --help
//
// Behavior:
// - Loads tokenizer.bin
// - Encodes the input string with BOS/EOS disabled (-1 each).
// - Prints space-separated token IDs.
// - If -r/--roundtrip is set, decodes pieces back to text and prints it.
//
// Notes:
// - Compatible with export_tokenizer_bin binary layout:
//     int32  max_token_length
//     repeat n_vocab times: float32 score, int32 byte_len, bytes token_bytes
// - We do a quick pass to count vocab size from the file to call
// read_tokenizer().

#include <errno.h>
#include <inttypes.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "tokenizer.hpp"

// ---------- Exit codes ----------
enum { EXIT_OK = 0, EXIT_USAGE = 2, EXIT_IO = 3, EXIT_BADFILE = 4, EXIT_NOMEM = 5 };

// ---------- CLI defaults ----------
#define DEFAULT_TOKENIZER_PATH "tokenizer.bin"
#define DEFAULT_PROMPT "Hello"
#define DEFAULT_MAX_TOKENS 8192

// ---------- File helpers ----------

static void die_perror(const char* msg, const char* path, int code) {
    if (path)
        fprintf(stderr, "%s '%s': %s\n", msg, path, strerror(errno));
    else
        fprintf(stderr, "%s: %s\n", msg, strerror(errno));
    exit(code);
}

static void die_msg(const char* msg, int code) {
    fprintf(stderr, "%s\n", msg);
    exit(code);
}

// Return both max_token_length and vocab_size by scanning the file once.
// On failure, exits with a descriptive error.
static void get_vocab_info(const char* path, int* out_max_len, int* out_vocab_size) {
    FILE* f = fopen(path, "rb");
    if (!f)
        die_perror("Failed to open", path, EXIT_IO);

    int32_t maxlen_le = 0;
    if (fread(&maxlen_le, sizeof(int32_t), 1, f) != 1) {
        fclose(f);
        die_msg("Bad tokenizer header (cannot read max_token_length).", EXIT_BADFILE);
    }

    int vocab = 0;
    for (;;) {
        float score;
        int32_t len_le;
        if (fread(&score, sizeof(float), 1, f) != 1)
            break; // EOF expected after last
        if (fread(&len_le, sizeof(int32_t), 1, f) != 1)
            break; // truncated?
        if (len_le < 0) {
            fclose(f);
            die_msg("Corrupt tokenizer: negative token length.", EXIT_BADFILE);
        }
        if (fseek(f, (long)len_le, SEEK_CUR) != 0) { // skip token bytes
            fclose(f);
            die_msg("Corrupt tokenizer: cannot seek over token bytes.", EXIT_BADFILE);
        }
        vocab++;
    }
    fclose(f);

    if (vocab <= 0)
        die_msg("Tokenizer appears empty or corrupt.", EXIT_BADFILE);

    if (out_max_len)
        *out_max_len = (int)maxlen_le;
    if (out_vocab_size)
        *out_vocab_size = vocab;
}

// ---------- CLI parsing ----------

static void print_usage(const char* prog) {
    fprintf(stderr,
            "Usage: %s -t <tokenizer.bin> -i <prompt> [-r] [--max-tokens N]\n"
            "Options:\n"
            "  -t, --tokenizer PATH   Path to tokenizer.bin "
            "(default: " DEFAULT_TOKENIZER_PATH ")\n"
            "  -i, --input TEXT       Prompt to encode (default: \"" DEFAULT_PROMPT "\")\n"
            "  -r, --roundtrip        Also decode pieces and print the reconstructed "
            "text\n"
            "      --max-tokens N     Capacity for encode output buffer (default: "
            "%d)\n"
            "  -h, --help             Show this help\n",
            prog, DEFAULT_MAX_TOKENS);
}

typedef struct {
    const char* tokenizer_path;
    const char* prompt;
    int roundtrip;
    int max_tokens;
} Options;

static void parse_args(int argc, char** argv, Options* opt) {
    opt->tokenizer_path = DEFAULT_TOKENIZER_PATH;
    opt->prompt = DEFAULT_PROMPT;
    opt->roundtrip = 0;
    opt->max_tokens = DEFAULT_MAX_TOKENS;

    for (int i = 1; i < argc; i++) {
        const char* arg = argv[i];
        if (strcmp(arg, "-t") == 0 || strcmp(arg, "--tokenizer") == 0) {
            if (i + 1 >= argc) {
                print_usage(argv[0]);
                exit(EXIT_USAGE);
            }
            opt->tokenizer_path = argv[++i];
        } else if (strcmp(arg, "-i") == 0 || strcmp(arg, "--input") == 0) {
            if (i + 1 >= argc) {
                print_usage(argv[0]);
                exit(EXIT_USAGE);
            }
            opt->prompt = argv[++i];
        } else if (strcmp(arg, "-r") == 0 || strcmp(arg, "--roundtrip") == 0) {
            opt->roundtrip = 1;
        } else if (strcmp(arg, "--max-tokens") == 0) {
            if (i + 1 >= argc) {
                print_usage(argv[0]);
                exit(EXIT_USAGE);
            }
            opt->max_tokens = atoi(argv[++i]);
            if (opt->max_tokens <= 0)
                die_msg("Invalid --max-tokens value.", EXIT_USAGE);
        } else if (strcmp(arg, "-h") == 0 || strcmp(arg, "--help") == 0) {
            print_usage(argv[0]);
            exit(EXIT_OK);
        } else {
            fprintf(stderr, "Unknown argument: %s\n", arg);
            print_usage(argv[0]);
            exit(EXIT_USAGE);
        }
    }
}

// ---------- Main ----------

int main(int argc, char** argv) {
    Options opt;
    parse_args(argc, argv, &opt);

    int max_token_len = 0;
    int vocab_size = 0;
    get_vocab_info(opt.tokenizer_path, &max_token_len, &vocab_size);

    Tokenizer tok;
    // read_tokenizer() should validate file structure internally.
    read_tokenizer(&tok, opt.tokenizer_path, vocab_size);

    int* ids = (int*)malloc((size_t)opt.max_tokens * sizeof(int));
    if (!ids)
        die_msg("Out of memory allocating token buffer.", EXIT_NOMEM);

    int n_ids = 0;
    // Disable BOS/EOS: we only test pure BPE behavior by default.
    encode(&tok, opt.prompt, /*bos_id=*/-1, /*eos_id=*/-1, ids, &n_ids, opt.max_tokens);

    // Print token IDs
    for (int i = 0; i < n_ids; i++) {
        if (i)
            printf(" ");
        printf("%d", ids[i]);
    }
    printf("\n");

    if (opt.roundtrip) {
        // Decode piece-by-piece using (prev -> curr) transitions for faithful
        // joins.
        for (int i = 0; i < n_ids; i++) {
            int prev = (i == 0) ? -1 : ids[i - 1];
            const char* piece =
                decode_piece(&tok, prev, ids[i]); // owned by tokenizer; printing is safe
            safe_printf(piece);
        }
        printf("\n");
    }

    free(ids);
    free_tokenizer(&tok);
    return EXIT_OK;
}
